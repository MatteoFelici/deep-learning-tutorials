{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification - Convolutional Neural Networks (CNN)\n",
    "\n",
    "For *structured* data we can use the \"classic\" Neural Network algorithm:\n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/simple-neural-network.png\"/></center>\n",
    "<br>\n",
    "\n",
    "\n",
    "- A node for each input feature\n",
    "- One or more intermediate layers called *hidden layers*, with one or more nodes\n",
    "- One layer to predict the output\n",
    "- Each node of a layer is connected with all the nodes from the previous and the next layers\n",
    "\n",
    "\n",
    "This complex structure, with lots of connections, does not fit very well with *unstructured* data, like images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image as data?\n",
    "\n",
    "We can decompose a 260 colored image into a set of 3 matrices:\n",
    "- each matrix has the same dimension, 260 rows and 194 columns\n",
    "- the 3 matrices represent the **RGB decomposition** of the image: red, green and blue\n",
    "- the cell (x, y) of the matrix z contains a number between 0 and 256. This number represents the intensity of the color z in the pixel (x, y)\n",
    "\n",
    "<br>\n",
    "<center><img src=\"./images/rgb_matrix.png\"/></center>\n",
    "<br>\n",
    "If we want to build a Neural Network model to distinguish if an image contains a cat or a dog, we would have 260x194x3 = 151320 nodes in the input layer. Even if we use a simple network, like with 1 hidden layer of 100 nodes and the output layer with a single node (dog/cat), we would have\n",
    "\n",
    "$$\\underbrace{(151320\\,x\\,100)}_{input\\,to\\,hidden}\\,\\,+ \\overbrace{(100\\,x\\,1)}^{hidden\\,to\\,output} = 15,132,100$$\n",
    "\n",
    "More than 15M connections (aka **parameters**) to learn from our ML processs! That's a lot!!!\n",
    "\n",
    "Beside that, we would lose every spacial information. The input pixels are put in one single parallel layer, and the network does not take into account the order of the input features. This means that the very upper-left pixel is treated as the more centered pixels, but we know that the latters should bring more information than the former."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
